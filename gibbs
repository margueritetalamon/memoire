rm(list = ls())


rmixtmod <- function(n,p,mu, sigma) {
  #Générateur de modèles de mélange gaussien de paramètres p, mu, sigma (variance)
  z <- sample(c(1:length(p)),n,replace = TRUE ,prob=p)
  return(list(x=rnorm(n,mu[z],sqrt(sigma[z])),z=z))
}


gibbs <- function(n_gibbs,x,gamma,s,l,eps,v,mu0,p0,sig0){ #n_gibbs est le nombre d'itérations de gibbs, x est l'échantillon, les autres paramètres sont les paramètres des lois a priori 
  
  #initialisation
  K <- length(mu0)
  p <- matrix(0,n_gibbs+1,K)
  mu <- matrix(0,n_gibbs+1,K)
  sig <- matrix(0,n_gibbs+1,K)
  like <- rep(0,n_gibbs+1)
  p[1,]<- p0
  mu[1,] <- mu0
  sig[1,] <- sig0
  like[1] <- loglikelihood_mm(x,p[1,],mu[1,],sig[1,])
  
  u <- matrix(0,K,length(x)) #matrice de proba
  z <- rep(0,length(x))
  me <- rep(0,K)
  ve <- rep(0,K)
  var_b <- rep(0,K)
  n <- rep(0,K)
  for (t in 1:n_gibbs){
    for (i in 1:length(x)){
      u[,i] <- p[t,]*dnorm(x[i],mu[t,],sqrt(sig[t,]))
      z[i] <- sample(1:K,size = 1,replace=TRUE,prob = u[,i])
    }
    n[as.numeric(levels(as.factor(z)))] <- table(z)
    p[t+1,] <- rdirichlet(1,gamma+n)
    for (j in 1:K){
      me[j] <- ((mean(x[z==j])*n[j])+(l[j]*eps[j]))/(l[j]+n[j])
      var_b[j] <- mean(x[z==j]^2)-mean(x[z==j])^2
      ve[j] <- s[j] + n[j]*var_b[j] + (l[j]*n[j]*(eps[j]-mean(x[z==j]))^2)/(n[j]+l[j])
      if (sum(z==j)==0){ #condition si il n'y a plus la composante j representée dans la matrice z
         me <- eps[j]
         ve <- s[j]
      }
     }
    mu[t+1,] <- rnorm(K,me,sqrt(sig[t,]/(n+l)))
    sig[t+1,] <- rinvgamma(K,(v+n)/2,ve/2)
    like[t+1] <- loglikelyhood_mixtmod(x,p[t+1,],mu[t+1,],sig[t+1,])
    
  }
  return(list(p=p,mu=mu,sig=sig,like=like))
  
}





dmixtmod <- function(x,p,mu,sig){
  #calcul la densité d'un modèle de mélange, x peut etre un reel un vecteur ou une matrice
  return(colSums(p*sapply(x,dnorm,mu,sqrt(sig))))
}


loglikelyhood_mixtmod<-function(x,p,mu,sigma){
  #evaluation de la fonction de vraisemblance sachant l'echantillon x pour les points p,mu, sigma
  return(sum(log(sapply(x,dmixtmod,p,mu,sigma))))
}



loglikelyhood_psig_fix <- function(mu_1, mu_2, x){
  #evaluation de la fonction de vraisemblance à p et sigma fixé sachant l'echantillon x pour le point mu
  output <- 0
  for(i in 1:length(x)) {
    output <- output + log(.7*dnorm(x[i], mu_1) + 0.3*dnorm(x[i], mu_2)) #valeurs à adapter
  }
  return(output)
}


pivotal_reordering<-function(x,x_gibbs){
  indice <- order(x_gibbs$like,decreasing = TRUE)[1]
  K <- ncol(x_gibbs$p)
  n_gibbs <- nrow(x_gibbs$p)
  ormu=matrix(0,n_gibbs,K)
  orsig=matrix(0,n_gibbs,K)
  orp=matrix(0,n_gibbs,K)
  pz_etoile=p_tau=matrix(0,n_gibbs,K)
  perma <- permn(1:K) #toutes les combinaisons de permutations 1:k
  entropy <- rep(0,factorial(K))
  pz_etoile <- t(x_gibbs$p[indice,]*sapply(x,dnorm,x_gibbs$mu[indice,],sqrt(x_gibbs$sig[indice,])))
  pz_etoile <- pz_etoile/rowSums(pz_etoile)
  for (t in 1:n_gibbs) {
    p_tau <- t(x_gibbs$p[t,]*sapply(x,dnorm,x_gibbs$mu[t,],sqrt(x_gibbs$sig[t,])))
    p_tau <- p_tau/rowSums(p_tau)
    
    for (j in 1:factorial(K)) {
      entropy[j] <- sum(colSums(pz_etoile*log(pz_etoile/p_tau[,perma[[j]]])))
    }
    ordre <- order(entropy,decreasing=TRUE)[factorial(K)] 
    ormu[t,] <- x_gibbs$mu[t,perma[[ordre]]] 
    orsig[t,] <- x_gibbs$sig[t,perma[[ordre]]] 
    orp[t,] <- x_gibbs$p[t,perma[[ordre]]]
  }
  return(list(mu_ordo=ormu,sig_ordo=orsig,p_ordo=orp))
}




